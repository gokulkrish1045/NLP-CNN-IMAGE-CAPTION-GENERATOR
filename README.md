# ğŸ–¼ï¸ Image Caption Generator using CNN & LSTM

![Image Caption Generator](result/image%20caption%20result%20.png)


Welcome to the **Image Caption Generator** repository! This project demonstrates how to generate captions for images using **Convolutional Neural Networks (CNN)** and **Long Short-Term Memory (LSTM)** models, combining computer vision and natural language processing techniques.

## ğŸŒŸ Project Overview

In this project, I build an **Image Caption Generator** by leveraging the power of deep learning techniques. Using a CNN to extract features from images and an LSTM network to generate descriptive captions, we combine the strengths of both models for an end-to-end solution. The model is trained and evaluated using the **Flickr dataset**, which provides a vast collection of images and corresponding textual descriptions.

## ğŸš€ Key Features

- **CNN (Convolutional Neural Networks)** for feature extraction from images.
- **LSTM (Long Short-Term Memory)** networks for sequence generation (captions).
- **End-to-end machine learning process** for building and evaluating the model.
- **Preprocessing pipeline** for images and textual data.
- **Evaluation metrics** to measure the performance of the generated captions.

## ğŸ”§ Tools & Technologies

- **Python** ğŸ
- **TensorFlow/Keras** for building deep learning models
- **CNN & LSTM** architecture for image captioning
- **Natural Language Processing (NLP)** techniques
- **Jupyter Notebook** for interactive development
- **Flickr dataset** for training the model

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ data/                   # Dataset folder (Flickr images and captions)
â”œâ”€â”€ notebooks/              # Jupyter notebooks for experimentation
â”œâ”€â”€ result/                 # Result of the project 
â”œâ”€â”€ src/                    # Source code for model training and evaluation
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ requirements.txt        # Dependencies required to run the project
```

## ğŸ How to Run

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/image-caption-generator.git
   cd image-caption-generator
   ```

2. **Install Dependencies**:
   Install the required Python libraries by running:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Jupyter Notebook**:
   Open the Jupyter notebook provided in the `notebooks/` directory and follow the steps to preprocess the data, train the model, and generate captions.

4. **Model Training**:
   To train the model, ensure the dataset is available and run the notebook `gokul-image-caption.ipynb`.

## ğŸ“Š Model Performance

The model's performance is evaluated using **BLEU score** and other NLP evaluation metrics. The notebook provides visualizations and metrics for assessing the quality of the generated captions.

## ğŸ¤– Future Enhancements

- Fine-tune the CNN-LSTM architecture for better performance.
- Experiment with larger datasets for improved accuracy.
- Deploy the model as a web application for real-time image caption generation.

## ğŸ“ License

This project is licensed under the MIT License .

## ğŸ™Œ Acknowledgments

- **Flickr** for the dataset used in this project.
- **Keras & TensorFlow** communities for providing powerful deep learning libraries.

---

